{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de vous offrir un aperçu des possibilités offertes par la bibliothèque [**scikit image**](https://scikit-image.org/). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage import feature\n",
    "from skimage import segmentation\n",
    "from skimage import morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activité 1 : binarisation\n",
    "\n",
    "Nous allons partir de l'image suivante, qui représente la lettre **V** en langue des signes :\n",
    "![](data/LSF/LSQ_v.jpg)\n",
    "\n",
    "Notre objectif est de produire une binarisation de cette image, de manière à avoir le fond en noir et la main en blanc :\n",
    "![](data/LSF/LSQ_v_bin.jpg)\n",
    "\n",
    "L'intérêt de cette binarisation est qu'elle permettra par la suitre de décrire la forme de la main, par exemple dans le cadre d'un programme de traduction automatique de la langue des signes. Mais nous n'irons pas jusque là. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Utiliser la fonction [imread](http://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.imread)  du module **io** pour charger l'image **data/LSF/LSQ_v.jpg** \n",
    "2. Afficher cette image avec les fonctions [imshow](http://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.imshow) et [show](http://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.show) du module **io** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#sol2\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"sol2\" class=\"collapse\">\n",
    "\n",
    "1. ```python\n",
    "from skimage.io import imread\n",
    "img = imread('data/LSF/LSQ_v.jpg')\n",
    "```\n",
    "\n",
    "2. ```python\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "io.show() #optional in Jupyter \n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant convertir l'image en niveaux de gris, c'est-à-dire ne conserver que la luminosité des pixels.\n",
    "1. Convertir l'image en niveaux de gris avec la fonction [rgb2gray](http://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.rgb2grey) du module **color**.\n",
    "2. Afficher l'image en niveaux de gris.\n",
    "\n",
    "Les niveaux de gris de l'image obtenue vont de 0 (noir) à 1 (blanc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#sol3\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"sol3\" class=\"collapse\">\n",
    "\n",
    "1. ```python\n",
    "from skimage.color import rgb2gray\n",
    "img_gray = rgb2gray(img)\n",
    "```\n",
    "\n",
    "2. ```python\n",
    "fig, (ax1, ax2)  = plt.subplots(1,2)\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(img_gray,  cmap=plt.cm.Greys_r)\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulons maintenant binariser cette image, c'est-à-dire choisir un niveau de gris de manière à ce que :\n",
    "* tous les pixels avec un niveau de gris inférieur soient considérés comme appartenant au fond et mis en noir ;\n",
    "* tous les pixels avec un niveau de gris supérieur ou égal soient considérés comme appartenant à la main et mis en blanc.\n",
    "\n",
    "Ce niveau de gris est appelé **seuil**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Créer un filtre qui extrait tous les pixels de la main. \n",
    "4. Mettre tous ces pixels en blancs et afficher l'image obtenue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#sol4\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"sol4\" class=\"collapse\">\n",
    "\n",
    "3. ```python\n",
    "mask = img_gray > 0.25\n",
    "mask\n",
    "```\n",
    "\n",
    "4. ```python\n",
    "img_gray[mask] = 1\n",
    "plt.imshow(img_gray, cmap=plt.cm.gray)\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scikit Image** propose plusieurs méthodes pour sélectionner un seuil de binarisation. Elle offre également une méthode très pratique, [try_all_threshold](http://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.try_all_threshold) qui permet de tester toutes ces méthodes et d'afficher les résultats obtenus. Nous allons ainsi pouvoir choisir celle qui produit le meilleur résultat avec notre image.\n",
    "\n",
    "> Pour afficher les résultats vous devez utiliser instruction **plt.show()** après avoir appellé la fonction **try_all_threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#sol5\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"sol5\" class=\"collapse\">\n",
    "\n",
    "```python\n",
    "from skimage.filters import try_all_threshold\n",
    "\n",
    "fig, ax = try_all_threshold(img_gray, verbose=False)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne reste plus qu'à choisir l'une des méthodes et produire une binarisation la plus propre possible de l'image. \n",
    "Modifiez le code suivant pour utiliser une fonction de binarisation plus pertinente : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_mean\n",
    "from matplotlib import pyplot\n",
    "\n",
    "thresh = threshold_mean(img_gray)\n",
    "binary = img_gray > thresh\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(8, 2.5))\n",
    "ax[0] = plt.subplot(1, 3, 1)\n",
    "ax[1] = plt.subplot(1, 3, 2)\n",
    "ax[2] = plt.subplot(1, 3, 3, sharex=ax[0], sharey=ax[0])\n",
    "\n",
    "ax[0].imshow(img_gray, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Original')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].hist(img_gray.ravel(), bins=256)\n",
    "ax[1].set_title('Histogram')\n",
    "ax[1].axvline(thresh, color='r')\n",
    "\n",
    "ax[2].imshow(binary, cmap=plt.cm.gray)\n",
    "ax[2].set_title('Thresholded')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activité 2 : télédétection\n",
    "\n",
    "Nous cherchons à identifier des fermes circulaires à partir d'images satellitaires. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source image : https://earthobservatory.nasa.gov/images/86079/todhia-arable-farm-in-saudi-arabia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lire le fichier **data/todhia_oli.jpg** contenant l'image satellitaire sur laquelle nous allons travailler.\n",
    "2. Convertir cette image en niveaux de gris.\n",
    "3. Binariser l'image de façon à faire resortir les fermes circulaires (en blanc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#sol6\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"sol6\" class=\"collapse\">\n",
    "\n",
    "1. ```python\n",
    "img = mpimg.imread('data/todhia_oli.jpg')\n",
    "```\n",
    "\n",
    "2. ```python\n",
    "img_gray = color.rgb2gray(img)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(img_gray, cmap=plt.cm.gray)\n",
    "ax.set_axis_off()\n",
    "```\n",
    "\n",
    "3. ```python\n",
    "from skimage.filters import threshold_otsu\n",
    "thresh = threshold_otsu(img_gray)\n",
    "binary = ~morphology.closing(img_gray > thresh)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(binary, cmap=plt.cm.gray)\n",
    "ax.set_axis_off()\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Identifier chacune des fermes, et représenter les à l'aide de couleurs différentes.\n",
    "5. Enregistrer le résultat de la détection dans une nouvelle image.\n",
    "\n",
    "La fonction `label` du module `morphology` permet d'identifier chaque objet séparé (composante connexe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#sol7\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"sol7\" class=\"collapse\">\n",
    "\n",
    "4. ```python\n",
    "# Add a label for each object\n",
    "label_image = morphology.label(binary)\n",
    "# Colorize each label\n",
    "image_label_overlay = color.label2rgb(label_image, image=img_gray,  bg_label=0)\n",
    "# Show the image and its labels\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(image_label_overlay)\n",
    "ax.set_axis_off()\n",
    "```\n",
    "\n",
    "5. ```python\n",
    "io.imwrite('todhia_oli_detected.png', image_label_overlay)\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les techniques de **détection de contours** peuvent aussi permettre d'identifier les fermes circulaires de cette image aérienne.\n",
    "Essayez de mettre en application les méthodes proposées dans le tutoriel suivant :\n",
    "[https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_blob.html](https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_blob.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#sol8\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"sol8\" class=\"collapse\">\n",
    "\n",
    "```python\n",
    "\n",
    "blobs = [(x[0],x[1],x[2]) for x in feature.blob_log(binary, \n",
    "                                                        min_sigma=15, \n",
    "                                                        max_sigma=25,\n",
    "                                                        threshold=0.2,\n",
    "                                                      )]\n",
    "# OR\n",
    "#blobs = [(x[0],x[1],x[2]) for x in feature.blob_dog(binary, \n",
    "#                                                        min_sigma=10, \n",
    "#                                                        max_sigma=25,\n",
    "#                                                        threshold=0.5,\n",
    "#                                                        overlap=0.6)]\n",
    "# OR\n",
    "#blobs = [(x[0],x[1],x[2]) for x in feature.blob_doh(binary, \n",
    "#                                                        min_sigma=10, \n",
    "#                                                        max_sigma=25,\n",
    "#                                                        threshold=0.045,\n",
    "#                                                      overlap=0.08)]\n",
    "\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "for blob in blobs:\n",
    "    y, x, r = blob\n",
    "    c = plt.Circle((x, y), r+1, color='red', linewidth=2, fill=False)\n",
    "    ax.add_patch(c)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title('Center Pivot Farms')\n",
    "\n",
    "plt.show()\n",
    "print('Number of center pivot farms detected: ' + str(len(blobs_dog)))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activité 3 : jeu des onze différences\n",
    "\n",
    "Retrouvez les onzes différences entre ces deux images.\n",
    "\n",
    "![](data/onze-erreurs1.jpg)\n",
    "![](data/onze-erreurs2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#sol9\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"sol9\" class=\"collapse\">\n",
    "\n",
    "```python\n",
    "top = color.rgb2gray(io.imread(\"data/onze-erreurs1.jpg\"))\n",
    "bot = color.rgb2gray(io.imread(\"data/onze-erreurs2.jpg\"))\n",
    "diff = top-bot\n",
    "plt.subplots(figsize=(15,10))\n",
    "plt.imshow(diff, cmap=plt.cm.gray)\n",
    "# Localisation dans l'image des différences\n",
    "blobs = [(x[0],x[1],x[2]) for x in feature.blob_log(diff, \n",
    "                                                        min_sigma=2.8, \n",
    "                                                        max_sigma=20,\n",
    "                                                        threshold=0.12,\n",
    "                                                      )]\n",
    "fig = plt.figure(figsize = (15,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "for blob in blobs:\n",
    "    y, x, r = blob\n",
    "    c = plt.Circle((x, y), r+1, color='red', linewidth=2, fill=False)\n",
    "    ax.add_patch(c)\n",
    "plt.imshow(io.imread(\"data/onze-erreurs2.jpg\"))\n",
    "```\n",
    "\n",
    "<img src=\"data/onze-erreurs-sol.jpg\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour aller plus loin\n",
    "* [**Scipy lectures notes**](http://www.scipy-lectures.org/advanced/image_processing/index.html)\n",
    "* Van der Walt S, Schönberger JL, Nunez-Iglesias J, Boulogne F, Warner JD, Yager N, Gouillart E, Yu T, The scikit-image contributors. 2014. **Scikit-image: image processing in Python.** https://doi.org/10.7717/peerj.453\n",
    "* **Filtrer le bruit d'une image** : [tutoriel](http://www.askaswiss.com/2016/12/how-to-denoise-images-in-python.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
